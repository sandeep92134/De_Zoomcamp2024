{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "00bc6543",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cd4a0f3d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/03/02 16:22:49 WARN Utils: Your hostname, codespaces-2912e2 resolves to a loopback address: 127.0.0.1; using 172.16.5.4 instead (on interface eth0)\n",
      "24/03/02 16:22:49 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "24/03/02 16:22:50 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "24/03/02 16:22:51 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder \\\n",
    "    .master(\"local[*]\") \\\n",
    "    .appName('test') \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eb3e4c36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3.5.0'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5236cebd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-rw-rw-rw- 1 vscode vscode 19M Dec  1  2022 data/raw/fhv/2019/10/fhv_tripdata_2019-10.csv.gz\n"
     ]
    }
   ],
   "source": [
    "!ls -lh data/raw/fhv/2019/10/fhv_tripdata_2019-10.csv.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f9743dbc-86c6-4c0d-961f-ea5582f77dba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cb192375-33d1-428e-b8e5-d830d1a10a41",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fhv_pd = pd.read_csv('data/raw/fhv/2019/10/fhv_tripdata_2019-10.csv.gz', nrows = 1000, keep_default_na=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b27ac29f-0b5c-443f-b87a-e105636a853c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dispatching_base_num</th>\n",
       "      <th>pickup_datetime</th>\n",
       "      <th>dropOff_datetime</th>\n",
       "      <th>PUlocationID</th>\n",
       "      <th>DOlocationID</th>\n",
       "      <th>SR_Flag</th>\n",
       "      <th>Affiliated_base_number</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>B00009</td>\n",
       "      <td>2019-10-01 00:23:00</td>\n",
       "      <td>2019-10-01 00:35:00</td>\n",
       "      <td>264</td>\n",
       "      <td>264</td>\n",
       "      <td></td>\n",
       "      <td>B00009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>B00013</td>\n",
       "      <td>2019-10-01 00:11:29</td>\n",
       "      <td>2019-10-01 00:13:22</td>\n",
       "      <td>264</td>\n",
       "      <td>264</td>\n",
       "      <td></td>\n",
       "      <td>B00013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>B00014</td>\n",
       "      <td>2019-10-01 00:11:43</td>\n",
       "      <td>2019-10-01 00:37:20</td>\n",
       "      <td>264</td>\n",
       "      <td>264</td>\n",
       "      <td></td>\n",
       "      <td>B00014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>B00014</td>\n",
       "      <td>2019-10-01 00:56:29</td>\n",
       "      <td>2019-10-01 00:57:47</td>\n",
       "      <td>264</td>\n",
       "      <td>264</td>\n",
       "      <td></td>\n",
       "      <td>B00014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>B00014</td>\n",
       "      <td>2019-10-01 00:23:09</td>\n",
       "      <td>2019-10-01 00:28:27</td>\n",
       "      <td>264</td>\n",
       "      <td>264</td>\n",
       "      <td></td>\n",
       "      <td>B00014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>B00111</td>\n",
       "      <td>2019-10-01 01:54:57</td>\n",
       "      <td>2019-10-01 03:10:06</td>\n",
       "      <td>264</td>\n",
       "      <td>100</td>\n",
       "      <td></td>\n",
       "      <td>B00111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>B00111</td>\n",
       "      <td>2019-10-01 01:07:06</td>\n",
       "      <td>2019-10-01 01:29:54</td>\n",
       "      <td>264</td>\n",
       "      <td>188</td>\n",
       "      <td></td>\n",
       "      <td>B00111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>B00112</td>\n",
       "      <td>2019-10-01 01:05:36</td>\n",
       "      <td>2019-10-01 01:36:28</td>\n",
       "      <td>264</td>\n",
       "      <td>228</td>\n",
       "      <td></td>\n",
       "      <td>B00112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>B00160</td>\n",
       "      <td>2019-10-01 01:20:00</td>\n",
       "      <td>2019-10-01 01:26:00</td>\n",
       "      <td>264</td>\n",
       "      <td>264</td>\n",
       "      <td></td>\n",
       "      <td>B00160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>B00225</td>\n",
       "      <td>2019-10-01 01:15:03</td>\n",
       "      <td>2019-10-01 01:22:57</td>\n",
       "      <td>264</td>\n",
       "      <td>232</td>\n",
       "      <td></td>\n",
       "      <td>B00225</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    dispatching_base_num      pickup_datetime     dropOff_datetime  \\\n",
       "0                 B00009  2019-10-01 00:23:00  2019-10-01 00:35:00   \n",
       "1                 B00013  2019-10-01 00:11:29  2019-10-01 00:13:22   \n",
       "2                 B00014  2019-10-01 00:11:43  2019-10-01 00:37:20   \n",
       "3                 B00014  2019-10-01 00:56:29  2019-10-01 00:57:47   \n",
       "4                 B00014  2019-10-01 00:23:09  2019-10-01 00:28:27   \n",
       "..                   ...                  ...                  ...   \n",
       "995               B00111  2019-10-01 01:54:57  2019-10-01 03:10:06   \n",
       "996               B00111  2019-10-01 01:07:06  2019-10-01 01:29:54   \n",
       "997               B00112  2019-10-01 01:05:36  2019-10-01 01:36:28   \n",
       "998               B00160  2019-10-01 01:20:00  2019-10-01 01:26:00   \n",
       "999               B00225  2019-10-01 01:15:03  2019-10-01 01:22:57   \n",
       "\n",
       "    PUlocationID DOlocationID SR_Flag Affiliated_base_number  \n",
       "0            264          264                         B00009  \n",
       "1            264          264                         B00013  \n",
       "2            264          264                         B00014  \n",
       "3            264          264                         B00014  \n",
       "4            264          264                         B00014  \n",
       "..           ...          ...     ...                    ...  \n",
       "995          264          100                         B00111  \n",
       "996          264          188                         B00111  \n",
       "997          264          228                         B00112  \n",
       "998          264          264                         B00160  \n",
       "999          264          232                         B00225  \n",
       "\n",
       "[1000 rows x 7 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_fhv_pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fc201a2a-f235-400f-a8f7-bd36e9eeb47a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StructType([StructField('dispatching_base_num', StringType(), True), StructField('pickup_datetime', StringType(), True), StructField('dropOff_datetime', StringType(), True), StructField('PUlocationID', StringType(), True), StructField('DOlocationID', StringType(), True), StructField('SR_Flag', StringType(), True), StructField('Affiliated_base_number', StringType(), True)])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.createDataFrame(df_fhv_pd).schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "490e1ffd-c120-4e5c-99cf-a1f231ba4d41",
   "metadata": {},
   "outputs": [],
   "source": [
    "schema = types.StructType([\n",
    "    types.StructField('dispatching_base_num', types.StringType(), True), \n",
    "    types.StructField('pickup_datetime', types.TimestampType(), True), \n",
    "    types.StructField('dropOff_datetime',types.TimestampType(), True), \n",
    "    types.StructField('PUlocationID', types.IntegerType(), True), \n",
    "    types.StructField('DOlocationID',types.IntegerType(), True), \n",
    "    types.StructField('SR_Flag', types.StringType(), True), \n",
    "    types.StructField('Affiliated_base_number', types.StringType(), True)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "68bc8b72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- dispatching_base_num: string (nullable = true)\n",
      " |-- pickup_datetime: timestamp (nullable = true)\n",
      " |-- dropOff_datetime: timestamp (nullable = true)\n",
      " |-- PUlocationID: integer (nullable = true)\n",
      " |-- DOlocationID: integer (nullable = true)\n",
      " |-- SR_Flag: string (nullable = true)\n",
      " |-- Affiliated_base_number: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = spark.read \\\n",
    "    .option(\"header\", \"true\") \\\n",
    "    .schema(schema) \\\n",
    "    .csv('data/raw/fhv/2019/10/fhv_tripdata_2019-10.csv.gz')\n",
    "\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "31482555-ab84-4db7-93cf-320bf1c62bbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------------------+-------------------+------------+------------+-------+----------------------+\n",
      "|dispatching_base_num|    pickup_datetime|   dropOff_datetime|PUlocationID|DOlocationID|SR_Flag|Affiliated_base_number|\n",
      "+--------------------+-------------------+-------------------+------------+------------+-------+----------------------+\n",
      "|              B00009|2019-10-01 00:23:00|2019-10-01 00:35:00|         264|         264|   NULL|                B00009|\n",
      "|              B00013|2019-10-01 00:11:29|2019-10-01 00:13:22|         264|         264|   NULL|                B00013|\n",
      "|              B00014|2019-10-01 00:11:43|2019-10-01 00:37:20|         264|         264|   NULL|                B00014|\n",
      "|              B00014|2019-10-01 00:56:29|2019-10-01 00:57:47|         264|         264|   NULL|                B00014|\n",
      "|              B00014|2019-10-01 00:23:09|2019-10-01 00:28:27|         264|         264|   NULL|                B00014|\n",
      "|     B00021         |2019-10-01 00:00:48|2019-10-01 00:07:12|         129|         129|   NULL|       B00021         |\n",
      "|     B00021         |2019-10-01 00:47:23|2019-10-01 00:53:25|          57|          57|   NULL|       B00021         |\n",
      "|     B00021         |2019-10-01 00:10:06|2019-10-01 00:19:50|         173|         173|   NULL|       B00021         |\n",
      "|     B00021         |2019-10-01 00:51:37|2019-10-01 01:06:14|         226|         226|   NULL|       B00021         |\n",
      "|     B00021         |2019-10-01 00:28:23|2019-10-01 00:34:33|          56|          56|   NULL|       B00021         |\n",
      "|     B00021         |2019-10-01 00:31:17|2019-10-01 00:51:52|          82|          82|   NULL|       B00021         |\n",
      "|              B00037|2019-10-01 00:07:41|2019-10-01 00:15:23|         264|          71|   NULL|                B00037|\n",
      "|              B00037|2019-10-01 00:13:38|2019-10-01 00:25:51|         264|          39|   NULL|                B00037|\n",
      "|              B00037|2019-10-01 00:42:40|2019-10-01 00:53:47|         264|         188|   NULL|                B00037|\n",
      "|              B00037|2019-10-01 00:58:46|2019-10-01 01:10:11|         264|          91|   NULL|                B00037|\n",
      "|              B00037|2019-10-01 00:09:49|2019-10-01 00:14:37|         264|          71|   NULL|                B00037|\n",
      "|              B00037|2019-10-01 00:22:35|2019-10-01 00:36:53|         264|          35|   NULL|                B00037|\n",
      "|              B00037|2019-10-01 00:54:27|2019-10-01 01:03:37|         264|          61|   NULL|                B00037|\n",
      "|              B00037|2019-10-01 00:08:12|2019-10-01 00:28:47|         264|         198|   NULL|                B00037|\n",
      "|              B00053|2019-10-01 00:05:24|2019-10-01 00:53:03|         264|         264|   NULL|                  #N/A|\n",
      "+--------------------+-------------------+-------------------+------------+------------+-------+----------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "58989b55",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df.repartition(6).write.parquet('data/pq/fhvhv/2019/10/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2c39f70a-6fa8-40b2-a730-632a41ce1c13",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.createOrReplaceTempView('fhv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f7489aea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6c2500fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "62610"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df \\\n",
    "    .withColumn('pickup_date', F.to_date(df.pickup_datetime)) \\\n",
    "    .filter(\"pickup_date = '2019-10-15'\") \\\n",
    "    .count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "be8d1250-9be3-4de7-86ba-a0fb199f3e0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 7:>                                                          (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------+--------+\n",
      "|to_date(pickup_datetime)|count(1)|\n",
      "+------------------------+--------+\n",
      "|              2019-10-15|   62610|\n",
      "+------------------------+--------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "Select to_date(pickup_datetime), count(1) from fhv\n",
    "where to_date(pickup_datetime) = '2019-10-15'\n",
    "GROUP BY to_date(pickup_datetime)\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae3f533b",
   "metadata": {},
   "source": [
    "**Q4**: Longest trip for each day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ccc45eca-f05a-40a2-9854-bb60570435bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 10:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------------------+-------------------+------------+------------+-------+----------------------+-----------------------------------------------------------------------------------------------------------------------+\n",
      "|dispatching_base_num|    pickup_datetime|   dropOff_datetime|PUlocationID|DOlocationID|SR_Flag|Affiliated_base_number|((unix_timestamp(dropOff_datetime, yyyy-MM-dd HH:mm:ss) - unix_timestamp(pickup_datetime, yyyy-MM-dd HH:mm:ss)) / 3600)|\n",
      "+--------------------+-------------------+-------------------+------------+------------+-------+----------------------+-----------------------------------------------------------------------------------------------------------------------+\n",
      "|              B02832|2019-10-11 18:00:00|2091-10-11 18:30:00|         264|         264|   NULL|                B02832|                                                                                                               631152.5|\n",
      "+--------------------+-------------------+-------------------+------------+------------+-------+----------------------+-----------------------------------------------------------------------------------------------------------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# What is the length of the longest trip in the dataset in hours?</br>\n",
    "spark.sql(\"\"\"\n",
    "Select *,((unix_timestamp(dropOff_datetime)-unix_timestamp(pickup_datetime))/3600) from fhv \n",
    "order by ((unix_timestamp(dropOff_datetime)-unix_timestamp(pickup_datetime))/3600)  desc limit 1\n",
    "\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7befe422",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['dispatching_base_num',\n",
       " 'pickup_datetime',\n",
       " 'dropOff_datetime',\n",
       " 'PUlocationID',\n",
       " 'DOlocationID',\n",
       " 'SR_Flag',\n",
       " 'Affiliated_base_number']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d10173a",
   "metadata": {},
   "source": [
    "**Q6**: Most common locations pair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e4b754d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_lookup_pd = pd.read_csv('taxi+_zone_lookup.csv', keep_default_na=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0e2db824-7401-4a81-a952-47944c24e0da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StructType([StructField('LocationID', LongType(), True), StructField('Borough', StringType(), True), StructField('Zone', StringType(), True), StructField('service_zone', StringType(), True)])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.createDataFrame(df_lookup_pd).schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c6ed8beb-538a-4039-923b-e8b0a97aae5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "lookup_schema = types.StructType([\n",
    "types.StructField('LocationID', types.IntegerType(), True), \n",
    "types.StructField('Borough', types.StringType(), True), \n",
    "types.StructField('Zone', types.StringType(), True), \n",
    "types.StructField('service_zone', types.StringType(), True)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d420480e-edcd-49a2-8ede-1ba733726ecc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_lookup = spark.read \\\n",
    "    .option(\"header\", \"true\") \\\n",
    "    .schema(lookup_schema) \\\n",
    "    .csv('taxi+_zone_lookup.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a05a32d0-a13d-452a-80fd-59af4b498e5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-------------+--------------------+------------+\n",
      "|LocationID|      Borough|                Zone|service_zone|\n",
      "+----------+-------------+--------------------+------------+\n",
      "|         1|          EWR|      Newark Airport|         EWR|\n",
      "|         2|       Queens|         Jamaica Bay|   Boro Zone|\n",
      "|         3|        Bronx|Allerton/Pelham G...|   Boro Zone|\n",
      "|         4|    Manhattan|       Alphabet City| Yellow Zone|\n",
      "|         5|Staten Island|       Arden Heights|   Boro Zone|\n",
      "|         6|Staten Island|Arrochar/Fort Wad...|   Boro Zone|\n",
      "|         7|       Queens|             Astoria|   Boro Zone|\n",
      "|         8|       Queens|        Astoria Park|   Boro Zone|\n",
      "|         9|       Queens|          Auburndale|   Boro Zone|\n",
      "|        10|       Queens|        Baisley Park|   Boro Zone|\n",
      "|        11|     Brooklyn|          Bath Beach|   Boro Zone|\n",
      "|        12|    Manhattan|        Battery Park| Yellow Zone|\n",
      "|        13|    Manhattan|   Battery Park City| Yellow Zone|\n",
      "|        14|     Brooklyn|           Bay Ridge|   Boro Zone|\n",
      "|        15|       Queens|Bay Terrace/Fort ...|   Boro Zone|\n",
      "|        16|       Queens|             Bayside|   Boro Zone|\n",
      "|        17|     Brooklyn|             Bedford|   Boro Zone|\n",
      "|        18|        Bronx|        Bedford Park|   Boro Zone|\n",
      "|        19|       Queens|           Bellerose|   Boro Zone|\n",
      "|        20|        Bronx|             Belmont|   Boro Zone|\n",
      "+----------+-------------+--------------------+------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_lookup.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "58d559d8-997d-444b-a46d-16a42f818482",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_lookup.createOrReplaceTempView('lookup')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c81a8890-425e-48bc-9209-0b730dc8072d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 13:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------+\n",
      "|                Zone|count(1)|\n",
      "+--------------------+--------+\n",
      "|         Jamaica Bay|       1|\n",
      "|Governor's Island...|       2|\n",
      "| Green-Wood Cemetery|       5|\n",
      "|       Broad Channel|       8|\n",
      "|     Highbridge Park|      14|\n",
      "|        Battery Park|      15|\n",
      "|Saint Michaels Ce...|      23|\n",
      "|Breezy Point/Fort...|      25|\n",
      "|Marine Park/Floyd...|      26|\n",
      "|        Astoria Park|      29|\n",
      "|    Inwood Hill Park|      39|\n",
      "|       Willets Point|      47|\n",
      "|Forest Park/Highl...|      53|\n",
      "|  Brooklyn Navy Yard|      57|\n",
      "|        Crotona Park|      62|\n",
      "|        Country Club|      77|\n",
      "|     Freshkills Park|      89|\n",
      "|       Prospect Park|      98|\n",
      "|     Columbia Street|     105|\n",
      "|  South Williamsburg|     110|\n",
      "+--------------------+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Using the zone lookup data and the FHV October 2019 data, what is the name of the LEAST frequent pickup location Zone?\n",
    "\n",
    "spark.sql(\"\"\"\n",
    "Select lookup.Zone, count(1) from fhv\n",
    "left join lookup on fhv.PUlocationID = lookup.LocationID\n",
    "group by lookup.Zone\n",
    "order by 2 asc\n",
    "\"\"\").show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
